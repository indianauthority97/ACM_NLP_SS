{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data for training & testing - http://10.5.30.132/acmss/hangmanTask\n",
    "- Send in your solutions - nlpsummerschool2017@gmail.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "  - We will give a test set of words called as `test`\n",
    "  - Use the same corpus `train` that we will provide for training.\n",
    "  - It is mandatory that you will have to predict one character at a time for the task\n",
    "  - For a word, output the list of all characters predicted by your method/system/function\n",
    "  - make sure that the list resembles the order of the prediction, so that we can caluclate the number of mistakes and the position at which you got the correct answer\n",
    "  - Ouptut all the predictions and the words as a json (your name)_hangmanT1.json\n",
    "  - key - word, value - list of all the predictions\n",
    "  - You will be evaluated based on the number of mistakes made and the number of correct words predicted\n",
    "  - You are allowed to make 11 wroing guessees for each word (during the tutorial we kept it at 8)\n",
    "  - Feel free to use or modify any of the functions used in the tutorial notebook.\n",
    "  - Please use the words only from training.txt (or a subset of training.txt) for building your model.\n",
    "  \n",
    "  ### Deadlines\n",
    "  \n",
    "  - **First version deadline - 19th June 11:59 PM**\n",
    "  - **Modifications - 20th June 7 PM**\n",
    "  - We will only consider the most recent version you have sent for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dict()\n",
    "a = {'aardvark':['a','n','k','b','r','z','y','x','u','v','j'], 'king':['e','s','k','m','o','j','r','t','v'],\n",
    "    'boy':['e','s','b','a','o','j','y']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('amrith_hangmanT1.json','w')\n",
    "json.dump(a,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'aardvark': [u'a',\n",
       "  u'n',\n",
       "  u'k',\n",
       "  u'b',\n",
       "  u'r',\n",
       "  u'z',\n",
       "  u'y',\n",
       "  u'x',\n",
       "  u'u',\n",
       "  u'v',\n",
       "  u'j'],\n",
       " u'boy': [u'e', u's', u'b', u'a', u'o', u'j', u'y'],\n",
       " u'king': [u'e', u's', u'k', u'm', u'o', u'j', u'r', u't', u'v']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.load(open('amrith_hangmanT1.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 (Optional)\n",
    "\n",
    "  - We will give a test set of words called as `test`\n",
    "  - You can use any training corpus of your choice\n",
    "  - **You need not make your predictions character by character**\n",
    "  - For a word, output the list predictions made by your method/system/function\n",
    "  - make sure that the list resembles the order of the prediction\n",
    "  - Ouptut all the predictions and the words as a json **(your name)_hangmanT2.json**\n",
    "  - key - word, value - list of all the predictions\n",
    "  - You will be evaluated based on the number of correct words predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = dict()\n",
    "a = {'aardvark':['ank','ard','x','u','vark'], 'king':['k','png','ing'],\n",
    "    'boy':['girl','boy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('amrith_hangmanT2.json','w')\n",
    "json.dump(a,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [The unreasonable effectiveness of Character-level Language Models](http://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139)\n",
    "- [Intro to RNNS](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
